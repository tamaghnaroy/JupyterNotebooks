{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def covariance(i, H):\n",
    "    if i==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return ((i-1)**(2*H) - 2*i**(2*H) + (i+1)**(2*H))/2\n",
    "\n",
    "def fBM_Levinson(m, H, L=1, cumm=1,_seed=None):\n",
    "    k=np.array(range(m))\n",
    "    if _seed:\n",
    "        np.random.seed(_seed)\n",
    "    scaling = (L/m) ** (2*H)\n",
    "    \n",
    "    # -- Covariance\n",
    "    cov = [covariance(i, H) for i in range(m)]\n",
    "    \n",
    "    # -- Initialization of the algorithm\n",
    "    y = np.random.normal(0,1,m)\n",
    "    fGn = np.zeros(m)\n",
    "    v1 = np.array(cov)\n",
    "    v2 = np.array([0] + cov[1:] + [0])\n",
    "    k = v2[1]\n",
    "    aa = np.sqrt(cov[0])\n",
    "    \n",
    "    # -- Levinson's algorithm\n",
    "    for j in range(1,m):\n",
    "        aa = aa * np.sqrt(1 - k*k)\n",
    "        v = k * v2[j:m] + v1[j-1:m-1]\n",
    "        v2[j:m] = v2[j:m] + k * v1[j-1:m-1]\n",
    "        v1[j:m] = v\n",
    "        bb = y[j] / aa\n",
    "        fGn[j:m] = fGn[j:m] + bb * v1[j:m]\n",
    "        k = -v2[j+1]/(aa*aa)\n",
    "    \n",
    "    # -- scaling and output\n",
    "    for i in range(m):\n",
    "        fGn[i] = scaling * fGn[i]\n",
    "        if cumm and i>0:\n",
    "            fGn[i] = fGn[i] + fGn[i-1]\n",
    "    \n",
    "    return fGn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73c3080>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = fBM_Levinson(m=1000, H=0.6, cumm=0, L=10)\n",
    "sample = np.cumprod(1+ret)\n",
    "plt.plot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7462f60>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H-P Filtering\n",
    "\n",
    "# Full Sample\n",
    "def apply_hp_filter(sample):\n",
    "    x = np.zeros((len(sample)-2, len(sample)), dtype=np.int)\n",
    "    for i, v in enumerate((1,-2, 1)):\n",
    "        np.fill_diagonal(x[:,i:], v)\n",
    "\n",
    "    I = np.eye(len(sample))\n",
    "    states = np.dot(np.linalg.inv(I + 10*np.dot(x.T, x)), sample)\n",
    "    return states\n",
    "\n",
    "# Halfsample\n",
    "s = apply_hp_filter(sample)\n",
    "s_2 = apply_hp_filter(sample[:int(len(sample)/2)])\n",
    "\n",
    "plt.plot(sample, color='gray', lw=3, alpha=0.4)\n",
    "plt.plot(s)\n",
    "plt.plot(s_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tamaghna\\Anaconda4\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9768860>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kernel Ridge regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "X = np.arange(len(sample))[:, None]\n",
    "poly = PolynomialFeatures(5)\n",
    "Feat = poly.fit_transform(X)\n",
    "\n",
    "clf = KernelRidge(alpha=1.0)\n",
    "clf.fit(Feat,sample) \n",
    "y_pred = clf.predict(Feat)\n",
    "\n",
    "plt.plot(sample)\n",
    "plt.plot(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
